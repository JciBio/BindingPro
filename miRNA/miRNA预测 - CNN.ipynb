{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random \n",
    "import re \n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import preprocessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_training_data = \"positive_training_dataset.txt\"\n",
    "negative_training_data = \"negative_training_dataset.txt\" \n",
    "positive_testing_data = \"positive_testing_dataset.txt\" \n",
    "negative_testing_data = \"negative_testing_dataset.txt\"#数据集的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNA_to_feature(str_rna, str_structure): \n",
    "#此函数将输入的RNA及其二级结构转化为输入的特征值 \n",
    "    # 接受两个字符串,第一个字符串是基因序列,第二个字符串是对应的二级结构 \n",
    "#     print(str_rna,str_structure)\n",
    "#     energy = re.findall(r'-{0,1}\\d{1,2}.\\d{1,2}', str_structure)[0] \n",
    "    \n",
    "    #利用正则表达式提取自由能 \n",
    "    rna, structure = '','' \n",
    "    \n",
    "    #初始化RNA和二级结构的数组 \n",
    "    for i in range(len(str_rna)): \n",
    "        #这个循环用来保证二级结构和编码同样长度，同时避免混入非RNA编码 \n",
    "        if str_rna[i] is not 'A' and str_rna[i] is not 'C' and str_rna[i] is not 'G' and str_rna[i] is not 'U': \n",
    "            continue \n",
    "        rna += str_rna[i] \n",
    "        structure += str_structure[i] \n",
    "        structure2int = [0 for i in range(len(structure))] \n",
    "        for i in range(len(structure)): \n",
    "        #这个循环将二级结构的编码转换为0，1编码，方便三元组编码的运用 \n",
    "            if structure[i] is '(' or ')': \n",
    "                structure2int[i]= 1 \n",
    "            if structure[i] is '.': \n",
    "                structure2int[i]= 0 \n",
    "    #接下来构造一个32维特征，用于储存三元组编码方式的特征值，以字典形式给出。并初始化为0。\n",
    "    rna_dic = {'A000': 0, 'A001': 0, 'A010': 0, 'A011': 0, 'A100': 0,'A101': 0, 'A110': 0, 'A111': 0, 'C000': 0, 'C001': 0, 'C010': 0, 'C011': 0, 'C100': 0,'C101': 0, 'C110': 0, 'C111': 0, 'G000': 0, 'G001': 0, 'G010': 0, 'G011': 0, 'G100': 0,'G101': 0, 'G110': 0, 'G111': 0, 'U000': 0, 'U001': 0, 'U010': 0, 'U011': 0, 'U100': 0,'U101': 0, 'U110': 0, 'U111': 0} \n",
    "    #然后搭建一个特征数组，方便判断使用。 \n",
    "    rna_index = ['A000', 'A001', 'A010', 'A011', 'A100','A101', 'A110', 'A111', 'C000', 'C001', 'C010', 'C011', 'C100','C101', 'C110', 'C111', 'G000', 'G001', 'G010', 'G011', 'G100','G101', 'G110', 'G111', 'U000', 'U001', 'U010', 'U011', 'U100','U101', 'U110', 'U111'] \n",
    "    for i in range(len(rna)-2): \n",
    "        str2all = rna[i]+ __builtins__.str(structure2int[i])+ __builtins__.str(structure2int[i+1])+ __builtins__.str(structure2int[i+2]) \n",
    "        rna_dic[str2all] += 1 \n",
    "    formalInput = [0 for i in range(32)] \n",
    "    #初始化最终特征向量formalInput，作为最后返回的特征向量。\n",
    "    count = 0; \n",
    "    for i in rna_index: \n",
    "        formalInput[count] = rna_dic[i] \n",
    "        count += 1\n",
    "#     print(energy)\n",
    "#     formalInput[32] = float(energy) \n",
    "    #print(formalInput)\n",
    "    #最后，将formalInput作为最终特征向量返回。 \n",
    "    return formalInput\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_form_x(data_path): \n",
    "#数据读取函数 \n",
    "    with open(data_path) as data: \n",
    "        #打开文件 \n",
    "        \n",
    "        form_x = [] \n",
    "        fp = data.readlines() \n",
    "        print(len(fp))\n",
    "        for i in range(0, len(fp), 3): \n",
    "            #每次跳两个读取 \n",
    "            \n",
    "            form_x.append(RNA_to_feature(fp[i + 1], fp[i + 2])) \n",
    "            #将奇数行（RNA编码）和偶数行（二级结构）一同输入，一起进行转换\n",
    "            \n",
    "    return form_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def data_process(): \n",
    "    X_train_correct = input_form_x(positive_training_data) \n",
    "    # 获取数据 \n",
    "    Y_train_correct = [] \n",
    "    for i in range(len(X_train_correct)): \n",
    "        Y_train_correct.append([1,0]) \n",
    "        \n",
    "    X_train_wrong = input_form_x(negative_training_data) \n",
    "    Y_train_wrong = [] \n",
    "    for i in range(len(X_train_wrong)):\n",
    "        Y_train_wrong.append([0,1])\n",
    "    X_test_correct = input_form_x(positive_testing_data) # 获取数据 \n",
    "    Y_test_correct = [] \n",
    "    for i in range(len(X_test_correct)): \n",
    "        Y_test_correct.append([1,0]) \n",
    "    X_test_wrong = input_form_x(negative_testing_data) \n",
    "    Y_test_wrong = [] \n",
    "    for i in range(len(X_test_wrong)): \n",
    "        Y_test_wrong.append([0,1])#采取独热编码进行二分类，是 与 不是。 \n",
    "    return X_train_correct,Y_train_correct,X_train_wrong ,Y_train_wrong ,X_test_correct ,Y_test_correct ,X_test_wrong ,Y_test_wrong\n",
    "    #然后将所有数据返回。\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7a361f831c67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 参数2 cmap 混淆矩阵中的颜色\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 参数3 title 标题\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'混淆矩阵'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGreens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# imshow() 表示绘制并显示二维图 有18个参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# 参数1 X 混淆矩阵中显示的数值 二维数组\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化权值\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=1,seed=1) #生成一个截断的正态分布\n",
    "    return tf.Variable(initial)\n",
    "    #return tf.Variable(tf.zeros(shape))\n",
    "\n",
    "#初始化偏置\n",
    "def bias_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=1,seed=1)\n",
    "    return tf.Variable(initial)\n",
    "    #return tf.Variable(tf.zeros(shape))\n",
    "\n",
    "#卷积层\n",
    "def conv2d(x,W):\n",
    "    #input tensor of shape [batch, in_height, in_width, in_channels]\n",
    "    #filter / kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    #strides[0]=strides[3]=1. strides[1]代表ｘ方向的步长，strids[2]代表ｙ方向的步长\n",
    "    #padding: A string from \"SAME\", \"VALID\"\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#池化层\n",
    "def max_pool(x):\n",
    "    #ksize [1,x,y,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "def multilayer_perceptron(x_train, x_test, y_train, y_test): \n",
    "\n",
    "\n",
    "    x_train_size = np.size(x_train, 0)\n",
    "    #定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 32]) \n",
    "    y = tf.placeholder(tf.float32, [None, 2])\n",
    "    \n",
    "    #改变x的格式转为４Ｄ的向量【batch, in_height, in_width, in_channels]\n",
    "    x_image = tf.reshape(x,[-1, 1, 32, 1])\n",
    "\n",
    "    #初始化第一个卷积层的权值和偏量\n",
    "    W_conv1 = weight_variable([1,3,1,64])#5*5的采样窗口，３２个卷积核从4个平面抽取特征\n",
    "    b_conv1 = bias_variable([64])#每一个卷积核一个偏置值\n",
    "\n",
    "    #把x_image和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool(h_conv1)#进行max-pooling,12-by-40\n",
    "    \n",
    "#     #初始化第二个卷积层的权值和偏置\n",
    "#     W_conv2 = weight_variable([2,2,32,64]) #5*5的采样窗口，64个卷积核从32个平面抽取特征\n",
    "#     b_conv2 = bias_variable([64]) #每一个卷积核一个偏置值\n",
    "\n",
    "#     #把H_pool1和权值向量进行卷积，再加上偏置值，然后应用于relu激活函数\n",
    "#     h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "#     h_pool2 = max_pool(h_conv2)#6-by-5\n",
    "    \n",
    "\n",
    "    #23*20的图片第一次卷积后还是23*20,第一次池化后变为12*10\n",
    "    #第二次卷积后为12*10,第二次池化后变为6*5\n",
    "    #进过上面操作后得到64张6*5的平面\n",
    "\n",
    "    #初始化第一全链接层的权值\n",
    "    W_fc1 = weight_variable([1*16*64,512]) #上一层有6*10*64个神经元,全连接层有1024个神经元\n",
    "    b_fc1 = bias_variable([512])\n",
    "\n",
    "    #把池化层2的输出扁平化为1维\n",
    "    h_pool2_flat = tf.reshape(h_pool1,[-1,1*16*64])\n",
    "    #求第一个全连接层的输出\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    #keep_prob用了表示神经元的输出概率\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    #初始化第二个全连接层\n",
    "    W_fc2 = weight_variable([512,2])\n",
    "    b_fc2 = bias_variable([2])\n",
    "\n",
    "    \n",
    "    #计算输出\n",
    "    prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)\n",
    "    # 结果存放在一个布尔列表中\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    #交叉熵代价函数\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=prediction))\n",
    "    \n",
    "    #使用AdamOptimizer进行优化\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    #求准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #初始化参数 \n",
    "        # Training cycle \n",
    "        for epoch in range(10000): \n",
    "            batch_index = random.randint(0, 1000) \n",
    "            #每一次从0-1000随机选出一个数，作为起始点 \n",
    "            batch_data = x_train[batch_index:batch_index + 32] \n",
    "            batch_labels = y_train[batch_index:batch_index + 32] \n",
    "            #在上面所选的起始点开始，拿出32组数据进行一次训练 \n",
    "            \n",
    "            sess.run(optimizer,feed_dict={x: batch_data, y: batch_labels, keep_prob: 0.9})\n",
    "            \n",
    "            \n",
    "            #进行训练 \n",
    "            if epoch%300 == 0: \n",
    "                print(epoch)\n",
    "                #accuracy = sess.run(accuracy, feed_dict={x: x_test, y: y_test, keep_prob: 1.0})\n",
    "                print(\"Accuracy:\", sess.run(accuracy, {x:x_test,y: y_test, keep_prob: 1.0}))\n",
    "                print(\"Loss:\", sess.run(cost, {x:x_test,y: y_test, keep_prob: 1.0}))\n",
    "\n",
    "                #每隔300次 输出对应的次数以及测试集所测试的准确度 \n",
    "        # Test model \n",
    "     \n",
    "        print(\"Total Accuracy:\", accuracy.eval({x:x_test, y:y_test, keep_prob: 1.0})) \n",
    "        #最后，当训练结束时，输出最终的准确率。\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452\n",
      "1452\n",
      "372\n",
      "372\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练集和测试集的随机分割\n",
    "X_train_correct, Y_train_correct, X_train_wrong, Y_train_wrong, X_test_correct, Y_test_correct ,X_test_wrong, Y_test_wrong = data_process() \n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_train + x_test, y_train + y_test, test_size=0.15,random_state=42) \n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train_correct + X_train_wrong + X_test_correct + X_test_wrong,\n",
    "                                                    Y_train_correct + Y_train_wrong + Y_test_correct + Y_test_wrong,\n",
    "                                                    test_size=0.15,random_state=42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Accuracy: 0.4863388\n",
      "Loss: 0.82692283\n",
      "300\n",
      "Accuracy: 0.58469945\n",
      "Loss: 0.7285625\n",
      "600\n",
      "Accuracy: 0.61202186\n",
      "Loss: 0.70123976\n",
      "900\n",
      "Accuracy: 0.568306\n",
      "Loss: 0.7449493\n",
      "1200\n",
      "Accuracy: 0.73224044\n",
      "Loss: 0.5810233\n",
      "1500\n",
      "Accuracy: 0.75956285\n",
      "Loss: 0.5542135\n",
      "1800\n",
      "Accuracy: 0.72677594\n",
      "Loss: 0.5864856\n",
      "2100\n",
      "Accuracy: 0.8251366\n",
      "Loss: 0.4881251\n",
      "2400\n",
      "Accuracy: 0.78688526\n",
      "Loss: 0.5249299\n",
      "2700\n",
      "Accuracy: 0.7978142\n",
      "Loss: 0.5154474\n",
      "3000\n",
      "Accuracy: 0.8306011\n",
      "Loss: 0.48265925\n",
      "3300\n",
      "Accuracy: 0.8196721\n",
      "Loss: 0.49267724\n",
      "3600\n",
      "Accuracy: 0.8469945\n",
      "Loss: 0.4631627\n",
      "3900\n",
      "Accuracy: 0.84153\n",
      "Loss: 0.47173154\n",
      "4200\n",
      "Accuracy: 0.863388\n",
      "Loss: 0.44987372\n",
      "4500\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894467\n",
      "4800\n",
      "Accuracy: 0.8579235\n",
      "Loss: 0.45533812\n",
      "5100\n",
      "Accuracy: 0.863388\n",
      "Loss: 0.44980568\n",
      "5400\n",
      "Accuracy: 0.863388\n",
      "Loss: 0.44987354\n",
      "5700\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894467\n",
      "6000\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.4389428\n",
      "6300\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894467\n",
      "6600\n",
      "Accuracy: 0.8469945\n",
      "Loss: 0.4662672\n",
      "6900\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43869698\n",
      "7200\n",
      "Accuracy: 0.852459\n",
      "Loss: 0.46080258\n",
      "7500\n",
      "Accuracy: 0.852459\n",
      "Loss: 0.46009356\n",
      "7800\n",
      "Accuracy: 0.8196721\n",
      "Loss: 0.49370822\n",
      "8100\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894476\n",
      "8400\n",
      "Accuracy: 0.89071035\n",
      "Loss: 0.4241961\n",
      "8700\n",
      "Accuracy: 0.8852459\n",
      "Loss: 0.42707434\n",
      "9000\n",
      "Accuracy: 0.89071035\n",
      "Loss: 0.422299\n",
      "9300\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894467\n",
      "9600\n",
      "Accuracy: 0.87431693\n",
      "Loss: 0.43894467\n",
      "9900\n",
      "Accuracy: 0.89617485\n",
      "Loss: 0.417087\n",
      "Total Accuracy: 0.89071035\n"
     ]
    }
   ],
   "source": [
    "#学习率设置\n",
    "learning_rate = 1e-4\n",
    "\n",
    "multilayer_perceptron(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x_train),len(y_train))\n",
    "# print(len(x_test),len(y_test))\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
